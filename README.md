# Project Overview

This README provides an overview of the methods used and the data collection process in this project.

The objective of this project is to apply Transfear Learning in the context of multi source Entity resolution. 

This is the project Pipline
![Project Workflow](workflow.jpeg)

Our project pipeline is designed to effectively transfer learning to target linkage tasks while ensuring that these target tasks maintain the same distribution as those used to train the models.

The pipeline begins with preprocessing the multiple data sources provided as input. Next, we generate feature vector datasets (linkage tasks) for each pair of datasets and apply a range of statistical and machine learning methods to identify similarities in their distributions.

Once the similarities are identified, we construct a similarity graph and use community detection algorithms to cluster the datasets. From each of these clusters, we select several models, train them, and use their capabilities to infer and predict feature vector datasets that have similar distributions.



## Methods

- **Statistical Methods**  
  Applied to compare the distributions between different record linkage tasks.

- **Graph Clustering**  
  Utilized to cluster the linkage tasks into strongly connected components.

- **Active Learning**  
  Employed to label selected tasks efficiently.

- **Machine Learning**  
  Algorithms are trained on linkage tasks labeled using active learning techniques.

- **Evaluation Metrics**  
  Used to assess the performance of the proposed framework.

## Data Collection

- **Camera Datasets**  
  Data collected from approximately 23 different sources.

### Repository structure

``` plain
â”œâ”€â”€ ğŸ“ data                   
â”‚   â”œâ”€â”€ ğŸ“ raw_data             <-- Unprocessed camera datasets
â”‚   â”œâ”€â”€ ğŸ“ cleaned_data         <-- Preprocessed camera datasets
â”‚   â”œâ”€â”€ ğŸ“ help_data            <-- Auxiliary data used during preprocessing
â”‚   â”œâ”€â”€ ğŸ“ linkage_tasks        <-- Linkage tasks for each pair of sources, with the first two columns containing record IDs
â”‚   â”œâ”€â”€ ğŸ“ linkage_tasks_labeled<-- Labeled linkage tasks generated using active learning
â”‚   â””â”€â”€ ğŸ“ ground_truth_data    <-- Ground truth data for the linkage tasks

â”œâ”€â”€ ğŸ“ results                  
â”‚   â”œâ”€â”€ ğŸ“ statistical_tests    <-- Contains images of statistical test results
â”‚   â”œâ”€â”€ ğŸ“ clustering           <-- Contains figures of the generated clusters
â”‚   â””â”€â”€ ğŸ“ linkage_results      <-- Precision, Recall, and F1-scores for the linkage tasks

â”œâ”€â”€ ğŸ“ meta_tl                  <-- Project codebase
â”‚   â”œâ”€â”€ ğŸ“ data_pre_processing      <-- Data preprocessing scripts
â”‚   â”‚   â”œâ”€â”€ ğŸ“ƒ data_cleaning.py     <-- Various methods used to clean raw data sources
â”‚   â”‚   â”œâ”€â”€ ğŸ“ƒ generate_ground_truth_data.py  <-- Generates ground truth labels for the record pairs
â”‚   â”‚   â””â”€â”€ ğŸ“ record_linkage           <-- Implementation of the record linkage process
â”‚   â”‚       â”œâ”€â”€ ğŸ“ƒ blocking.py          <-- Methods for blocking
â”‚   â”‚       â”œâ”€â”€ ğŸ“ƒ comparison.py        <-- Methods for comparing records sharing the same blocking keys
â”‚   â”‚       â”œâ”€â”€ ğŸ“ƒ load_data_set.py     <-- Prepares datasets for the record linkage process
â”‚   â”‚       â””â”€â”€ ğŸ“ƒ record_linkage_main.py <-- Main script for record linkage
â”‚   â”œâ”€â”€ ğŸ“ƒ statistical_tests.py     <-- Implementations of statistical methods for comparing linkage task distributions
â”‚   â”œâ”€â”€ ğŸ“ƒ graph_clustering.py      <-- Methods for graph clustering of linkage tasks
â”‚   â”œâ”€â”€ ğŸ“ƒ model_selection.py       <-- Methods for selecting linkage tasks from clusters
â”‚   â”œâ”€â”€ ğŸ“ƒ active_learning.py       <-- Active learning methods for labeling selected tasks
â”‚   â”œâ”€â”€ ğŸ“ƒ transfear_learning.py    <-- Apply the trained selected linkage tasks on the other linkage tasks
â”‚   â”œâ”€â”€ ğŸ“ƒ evaluation.py            <-- Implementation of evaluation methods for assessing the proposed methods
â”‚   â”œâ”€â”€ ğŸ“ƒ utils.py                 <-- Helper functions used throughout the project

â”œâ”€â”€ ğŸ“ƒ main.py                     <-- Main script for the project
â”œâ”€â”€ ğŸ“ƒ requirements.txt            <-- Libraries and dependencies
â””â”€â”€ ğŸ“ƒ README.md                   <-- Project documentation

```








































